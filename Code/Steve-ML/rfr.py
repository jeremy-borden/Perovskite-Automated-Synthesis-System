# -*- coding: utf-8 -*-
"""RFR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fEzJBQATwEieGl3j5qUS0TRGFcH6EODT

# **1. Importing Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from skopt import gp_minimize
from skopt.space import Real
from skopt.utils import use_named_args
import pickle

"""# **2. Uploading and Loading Data**"""

data = pd.read_excel("ml_test_data.xlsx")

"""# **3. Initialise Input and Output Data for Training and Testing**

"""

# Calculate Bandgap
data['Bandgap'] = 1240 / data['Plwave']

# define input/features (X) and target/output (y)
X = data[['PL intensity', 'Plwave']]
y = data['Bandgap']

# train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Training data shape:", X_train.shape, y_train.shape)
print("Testing data shape:", X_test.shape, y_test.shape)

"""(30, 2): 30 samples, each with 2 features (PL intensity & Plwave).

(30,): 30 target values (Bandgap), a 1D array.

(8, 2): 8 test samples, each with 2 features.

(8,): 8 test target values, also a 1D array.

# **4. Model Training and Making Predictions**
"""

# Initialize our Random Forest Regressor model
rfr_model = RandomForestRegressor(n_estimators=100, random_state=42)
rfr_model.fit(X_train, y_train)
y_pred = rfr_model.predict(X_test)

"""# **5. Model Evaluation**"""

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Absolute Error (MAE): {mae}")
print(f"R² Score: {r2}")

"""Lower MAE is better, and this value indicates that the model is highly accurate in its predictions.

R² score close to 1 is excellent, meaning the model fits the data very well.0.99934 is a strong result and indicates that your model is doing a great job predicting the target variable.

# **6. Function to display intensity and wavelength values**
"""

def display_intensity_wavelength(data):
    # new DataFrame with Ink Sample, intensity, and wavelength values
    combined_data = pd.DataFrame({
        'Ink Sample': data['Ink_Sample'],
        'PL Intensity': data['PL intensity'],
        'PL Wavelength': data['Plwave']
    })

    # Count
    count_intensity = len(data['PL intensity'])
    count_wavelength = len(data['Plwave'])

    # Print
    print("Ink Sample, PL Intensity, and Wavelength Values:")
    print(combined_data.to_string(index=False, col_space=20))
    print(f"\nCount of PL Intensity Values: {count_intensity}")
    print(f"Count of PL Wavelength Values: {count_wavelength}")

# Function Call
display_intensity_wavelength(data)

"""### 1.   **A strong, positive relationship between PL intensity and bandgap means stable and efficient bandgap.**

### **2.   PL wavelength decreases, the bandgap increases.**

# **7. Function to calculate and display bandgap values**
"""

#Bandgap Calculation
data['Bandgap'] = 1240 / data['Plwave']

def display_bandgap_values(data):
    # DataFrame for bandgap, intensity, wavelength, and ink sample
    bandgap_data = pd.DataFrame({
        'Ink Sample': data['Ink_Sample'],
        'PL Intensity': data['PL intensity'],
        'PL Wavelength': data['Plwave'],
        'Bandgap': data['Bandgap']
    })

    print("\nInk Sample, Bandgap Values with Corresponding Intensity and Wavelength:")
    # Print
    print(bandgap_data.to_string(index=False, col_space=20))
    print(f"\nTotal Number of Bandgap Values: {len(bandgap_data)}")

# Function Call
display_bandgap_values(data)

"""# **8. Function to calculate the efficiency score based on the existing dataset**"""

def calculate_efficiency_score(data):
    # Calculate raw efficiency score
    data['Raw Efficiency Score'] = (1 / data['Plwave']) * data['PL intensity']

    # Normalize efficiency score between 0-100
    data['Efficiency Score'] = (data['Raw Efficiency Score'] - data['Raw Efficiency Score'].min()) / \
                               (data['Raw Efficiency Score'].max() - data['Raw Efficiency Score'].min()) * 100

    return data

# Function call
data_with_efficiency = calculate_efficiency_score(data)

# Print
print("\nData with Efficiency Scores:")
efficiency_data = data_with_efficiency[['Ink_Sample', 'PL intensity', 'Plwave', 'Raw Efficiency Score', 'Efficiency Score']]
print(efficiency_data.to_string(index=False, col_space=20))

# The most efficient entry based on the highest efficiency score
most_efficient = data_with_efficiency.loc[data_with_efficiency['Efficiency Score'].idxmax()]
print("\nMost Efficient Entry (Highest Efficiency Score):")
print(f"Ink Sample: {most_efficient['Ink_Sample']}")
print(f"PL Intensity: {most_efficient['PL intensity']}")
print(f"PL Wavelength: {most_efficient['Plwave']}")
print(f"Raw Efficiency Score: {most_efficient['Raw Efficiency Score']}")
print(f"Efficiency Score: {most_efficient['Efficiency Score']}")

"""**The highest efficiency score of 100 represents the best combination of PL intensity and PL wavelength that results in the highest normalized efficiency score based on the inverse relationship with PL wavelength.**

# **10. Visualization Functions**

## **i). Scatter Plot of Actual vs Predicted Values**
"""

# all data points
y_pred_all = rfr_model.predict(X)

plt.figure(figsize=(10, 6))
plt.scatter(y, y_pred_all, alpha=0.6, edgecolor=None, c='blue', label='All Data')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Prediction Line')
plt.xlabel('Actual Bandgap')
plt.ylabel('Predicted Bandgap')
plt.title('Actual vs Predicted Bandgap (Random Forest)')
plt.legend()
plt.grid()
plt.show()

"""**The closer the points are to the line, the better the model’s performance. Wider spread indicates poor predictive accuracy.**

## **ii). Residual Plot vs Predicted Values**
"""

# all data points
y_pred_all = rfr_model.predict(X)

# Residuals: all data points
residuals_all = y - y_pred_all

plt.figure(figsize=(10, 6))
plt.scatter(y_pred_all, residuals_all, alpha=0.6, edgecolor=None, c='green', label='All Data')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.xlabel('Predicted Bandgap')
plt.ylabel('Residuals')
plt.title('Residuals vs Predicted Bandgap (All Data)')
plt.legend()
plt.grid()
plt.show()

"""**Indicates that the model is unbiased and captures the data well. Ideally, residuals should cluster close to zero.**

**(residuals = actual - predicted)**

## **iii). Density Distribution Plot of Residuals**
"""

# Calculate residuals
y_pred_all = rfr_model.predict(X)
residuals_all = y - y_pred_all

# Plot
plt.figure(figsize=(10, 6))
sns.kdeplot(residuals_all, fill=True, color='blue', alpha=0.6, label='Residual Density')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Density Distribution of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Density')
plt.legend()
plt.grid()
plt.show()

"""**The density plot is centered at 0 and spread is minimal, the model is performing well across the dataset**

## **iv). Model coefficients and Plot for feature importances**

To display the importance of each feature in predicting the target variable (Bandgap).

 Helps prioritize variables for feature engineering or model refinement.
"""

feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rfr_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

# Plot
plt.figure(figsize=(10, 6))
plt.barh(feature_importances['Feature'], feature_importances['Importance'], color='skyblue')
plt.xlabel('Feature Importance')
plt.title('Feature Importances from Random Forest Regressor')
plt.gca().invert_yaxis()
plt.grid(axis='x')
plt.show()

# Feature Importance Values
feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rfr_model.feature_importances_
})
print("\nFeature Importances:")
print(feature_importances)

"""**Higher bars: Features that contribute more to the prediction, in our case, it's the PL Wavelength**

***Lower bars: Features with minimal contribution, which could potentially be removed or deprioritized. ***

# **11. Save the trained model**
"""

# Saving the trained model using pickle
with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(rfr_model, file)

"""# **12. Optimization Loop beyond the dataset using Random Search:**

It picks random values for PL Intensity and PL Wavelength within the specified ranges and evaluates the Efficiency Score for each combination.
 It stores the best combination of parameters that produces the highest efficiency score and outputs the optimal values at the end.
"""

# set random samples
num_samples = 1000

# subset
pl_intensity_samples = np.random.uniform(3000, 2000000, num_samples)
pl_wavelength_samples = np.random.uniform(800, 840, num_samples)

def efficiency_score(pl_intensity, pl_wavelength):
    return (1 / pl_wavelength) * pl_intensity

# Compute efficiency scores
results = []
for intensity, wavelength in zip(pl_intensity_samples, pl_wavelength_samples):
    score = efficiency_score(intensity, wavelength)
    results.append((intensity, wavelength, score))

results_df = pd.DataFrame(results, columns=['PL Intensity', 'PL Wavelength', 'Efficiency Score'])

# Find best parameters
best_row = results_df.loc[results_df['Efficiency Score'].idxmax()]
optimal_intensity, optimal_wavelength, optimal_score = best_row

# Save
results_df.to_csv("random_search_results.csv", index=False)

# Plot
plt.figure(figsize=(10, 6))
plt.scatter(results_df['PL Wavelength'], results_df['PL Intensity'], c=results_df['Efficiency Score'], cmap='viridis', s=100)
plt.colorbar(label='Efficiency Score')
plt.title('Random Search: PL Intensity vs. PL Wavelength (Efficiency Score)', fontsize=16)
plt.xlabel('PL Wavelength', fontsize=14)
plt.ylabel('PL Intensity', fontsize=14)
plt.grid()
plt.savefig("random_search_plot.png")
plt.show()

# Print
print(f"Optimal Parameters Found (Random Search):\nPL Intensity: {optimal_intensity}\nPL Wavelength: {optimal_wavelength}\nMaximum Efficiency Score: {optimal_score}")

"""# **13. Optimization Loop beyond the dataset using Bayesian Optimization:**

Bayesian optimization builds a probabilistic model (like Gaussian Processes) of the objective function and uses it to decide where to evaluate next. It balances exploration (trying new areas) and exploitation (focusing on promising areas).

 In simpler words, it uses a probabilistic model to predict where the next evaluation should be and tries to balance exploration and exploitation.
"""

# Range
space = [
    Real(3000, 2000000, name='PL_intensity'),
    Real(800, 840, name='PL_wavelength')
]

# efficiency score function
def efficiency_score(params):
    pl_intensity, pl_wavelength = params
    raw_score = (1 / pl_wavelength) * pl_intensity
    return -raw_score  # gp_minimize always trys to minimise but we want to get maximum values ie., highest efficiency so we negate the raw score

# Bayesian Optimization
res = gp_minimize(efficiency_score, space, n_calls=50, random_state=42)
optimal_intensity = res.x[0]
optimal_wavelength = res.x[1]
optimal_score = -res.fun

# store results in a  DataFrame
results_df = pd.DataFrame({
    'PL Intensity': [x[0] for x in res.x_iters],
    'PL Wavelength': [x[1] for x in res.x_iters],
    'Raw Efficiency Score': [-efficiency_score(x) for x in res.x_iters]
})
results_df['Efficiency Score'] = (results_df['Raw Efficiency Score'] - results_df['Raw Efficiency Score'].min()) / \
                                 (results_df['Raw Efficiency Score'].max() - results_df['Raw Efficiency Score'].min()) * 100

# CSV
results_df.to_csv("optimization_results.csv", index=False)

# Visualization 1: Efficiency Score over Iterations
plt.figure(figsize=(10, 6))
plt.plot(range(len(results_df)), results_df['Efficiency Score'], marker='o', label='Efficiency Score')
plt.title('Efficiency Score over Iterations', fontsize=16)
plt.xlabel('Iteration', fontsize=14)
plt.ylabel('Efficiency Score', fontsize=14)
plt.grid()
plt.legend()
plt.savefig("efficiency_score_over_iterations.png")
plt.show()

# Visualization 2: 2D Scatter Plot for PL Intensity vs. PL Wavelength
plt.figure(figsize=(10, 6))
sc = plt.scatter(results_df['PL Wavelength'],
                 results_df['PL Intensity'],
                 c=results_df['Efficiency Score'],
                 cmap='viridis', s=100)
plt.colorbar(sc, label='Efficiency Score')
plt.title('PL Intensity vs. PL Wavelength (Efficiency Score)', fontsize=16)
plt.xlabel('PL Wavelength', fontsize=14)
plt.ylabel('PL Intensity', fontsize=14)
plt.grid()
plt.savefig("pl_intensity_vs_wavelength.png")
plt.show()

# last 10 results
print("\nOptimization Results (Last 10 Results):")
print(results_df.tail(10).to_string(index=False))

# optimal parameters
print(f"Optimal Parameters Found:\nPL Intensity: {optimal_intensity}\nPL Wavelength: {optimal_wavelength}\nMaximum Efficiency Score: {optimal_score}")

"""# **14. Function to Predict Bandgap for New Ink Parameters**"""

def predict_bandgap_rfr(pl_intensity, pl_wave):
    # DataFrame for the new input
    new_data = pd.DataFrame({'PL intensity': [pl_intensity], 'Plwave': [pl_wave]})
    # Predict bandgap using our RFR model
    predicted_bandgap = rfr_model.predict(new_data)
    # Print
    print(f"Input Parameters:\nPL Intensity: {pl_intensity}\nPL Wavelength: {pl_wave}")
    print(f"Predicted Bandgap: {predicted_bandgap[0]}")
    return predicted_bandgap[0]

# Sample Inputs
optimal_pl_intensity = 1000560
optimal_pl_wave = 824.0
predicted_bandgap_rfr = predict_bandgap_rfr(optimal_pl_intensity, optimal_pl_wave)

# predictions for all data
y_all_pred_rfr = rfr_model.predict(X)

# scatter plot w/o. new data
plt.figure(figsize=(10, 6))
plt.scatter(y, y_all_pred_rfr, alpha=0.6, edgecolors='k', label='All Data Points (RFR)')

# scatter plot w. new data
plt.scatter(predicted_bandgap_rfr, predicted_bandgap_rfr, color='green', s=100, edgecolor='black', label='Predicted Bandgap (New Input)')

# prediction line
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Perfect Prediction Line')
plt.xlabel('Actual Bandgap')
plt.ylabel('Predicted Bandgap')
plt.title('Actual vs Predicted Bandgap (RFR Model, Including New Prediction)')
plt.legend()
plt.grid()
plt.show()